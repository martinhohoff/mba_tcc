%% USPSC-Cap2-Desenvolvimento.tex


\chapter[Metodologia]{Metodologia}

    \section{Fundamentos}

        \subsection{Tratamento de Dados}
            Em relação às etapas de tratamento de dados necessárias em um projeto de aprendizagem de máquina, vamos nos deter a dois pontos principais: outliers e dados faltantes.\newline 

            \textbf{Dados espúrios}\par
            Um outlier "é uma observação que se encontra a uma distância anormal de outros valores em uma amostra aleatória de uma população. (...) Outliers podem distorcer a distribuição sumária de valores de atributos em estatísticas descritivas como média e desvio padrão e em gráficos como histogramas e gráficos de dispersão, comprimindo o corpo dos dados." \cite{portal2018}\newline

            \textbf{Dados faltantes}\par
            Durante o desenvolvimento de um modelo, "é comum existirem, dentre as variáveis preditivas, algumas que possuem dados não preenchidos (missings), sendo necessário assim adotar algum procedimento para tratamento destas variáveis." \cite{assuncao2012}\newline

	    \subsection{Bliblioteca Scikit-learn}
	    O scikit-learn "é uma biblioteca da linguagem Python desenvolvida especificamente para aplicação prática de machine learning. Esta biblioteca dispõe de ferramentas simples e eficientes para análise preditiva de dados, é reutilizável em diferentes situações, possui código aberto, sendo acessível a todos e foi construída sobre os pacotes NumPy, SciPy e matplotilib". \cite{didatica2020}

        \subsection{Algoritmos de regressão}
	    De acordo com a Oper Data \cite{oper2020}, os problemas de Machine Learning "são divididos em três subáreas principais: classificação, regressão e clustering.".
	    
	    Entre os algoritmos de classificação e regressão, podemos destacar, para os fins desse trabalho:\newline

		  %  \textbf{Árvores de decisão}\par
		  %  A árvore de decisão "está entre os métodos mais comuns aplicados ao aprendizado de máquina. Tais algoritmos subdividem progressivamente os dados em conjuntos cada vez menores e mais específicos, em termos de seus atributos, até atingirem um tamanho simplificado o bastante para ser rotulado. Para isso é necessário treinar o modelo com dados previamente rotulados, de modo a aplicá-lo a dados novos." \cite{digitalhouse2021}\newline

		    \textbf{Regressão logística}\par
		    A regressão logística "é uma técnica estatística que tem como objetivo produzir, a partir de um conjunto de observações, um modelo que permita a predição de valores tomados por uma variável categórica, frequentemente binária, em função de uma ou mais variáveis." \cite{gonzalez2018}\newline

		    \textbf{Support vector machines}\par
		     Algoritmos de máquina de vetores de suporte (em inglês, Support Vector Machines, ou SVM) "têm como objetivo a determinação de limites de decisão que produzam uma separação ótima entre classes por meio da minimização dos erros." \cite{nascimento2009}\newline

		  %  \textbf{Random forest}\par
		  %  O algoritmo de Random Forest leva esse nome por "criar muitas árvores de decisão, de maneira aleatória, formando o que podemos enxergar como uma floresta, onde cada árvore será utilizada na escolha do resultado final". \cite{didatica2019}\newline

		  %  \textbf{Redes neurais}\par
		  %  Redes Neurais "são um formato de estrutura de dados inspirada nas redes de neurônios do cérebro humano (...) organizadas em uma lógica de camadas e nós dentro dos códigos de programação, sugerindo uma estrutura vagamente similar ao que ocorre com os neurônios".\cite{ilumeo2020}

        \subsection{Seleção de atributos e regressão por stepwise}
            Dada a existência de um grande número de atributos em um dataset, é necessário escolher aqueles que melhor servirão para treinamento de um modelo.
        
            Uma das possibilidades para essa seleção é a regressão por stepwise. Ela é usada "para determinar os recursos mais importantes para um modelo usando a eliminação recursiva".\cite{deepdive2020}, (tradução do autor)
            
            "Comece com um modelo vazio (que inclui apenas a interceptação) e, a cada vez, a variável que possui uma estimativa de parâmetro associada com o menor valor de p é adicionada ao modelo (passo de avanço). Depois de adicionar cada nova variável no modelo, o algoritmo irá olhar para os p-valores de todas as outras estimativas de parâmetros que foram adicionadas ao modelo anteriormente e removê-los se o p-valor exceder um certo valor (retrocesso). O algoritmo para quando nenhuma variável pode ser adicionada ou removida dados os valores de limite" \cite{deepdive2020} (tradução do autor).\newline

	    \subsection{Avaliação de modelos}
	    Para comparar e selecionar modelos de aprendizagem de máquina, é necessário definir métricas que possam ser utilizadas como critério de avaliação. Entre elas, podemos destacar três:\newline

            \textbf{Área sob a curva ROC}\par
            A curva ROC ajuda a encontrar o melhor threshold na regressão logística, "resumindo a compensação entre a taxa de verdadeiro positivo e a taxa de falso positivo para um modelo preditivo usando diferentes limites de probabilidade." \cite{mastery2021} (tradução do autor)\newline

            \textbf{Precisão}\par
	        A medida de precisão, caracterizada pela divisão dos verdadeiros positivos pelo total de predições positivas, "fala sobre quão preciso é seu modelo em relação aos positivos previstos, quantos deles são realmente positivos. A precisão é uma boa medida para determinar quando os custos do falso positivo são altos." \cite{towards2020} (tradução do autor)\newline

	        \textbf{Revocação}\par
	        A revocação, que é a razão entre os valores preditos como positivos e o total de valores reais positivos no dataset, "calcula quantos dos positivos reais nosso modelo captura, rotulando-o como positivo (positivo verdadeiro). Aplicando o mesmo entendimento, sabemos que o Recall será a métrica do modelo que usaremos para selecionar nosso melhor modelo quando houver um alto custo associado ao Falso Negativo." \cite{towards2020} (tradução do autor)

	        \textbf{F-1 Score}\par
	        A pontuação F1 " é necessária quando você deseja buscar um equilíbrio entre precisão e recuperação. (...)A Pontuação F1 pode ser um melhor medida a ser usada se precisarmos buscar um equilíbrio entre precisão e recall e houver uma distribuição de classe desigual (grande número de negativos reais).". \cite{towards2020} (tradução do autor).\newline

    \section{Trabalhos relacionados}

        \textbf{Popularidade de filmes}\par

        Entre os trabalhos já realizados sobre a aplicação de algoritmos de aprendizagem de máquina na predição de popularidade de filmes, podemos destacar o artigo "Prediction of Movies popularity Using Machine Learning Techniques" ("Previsão da popularidade de filmes usando técnicas de aprendizado de máquina", tradução do autor).\par
        A metodologia utilizada pelo autor é descrita da seguinte forma: "criamos um conjunto de dados e, em seguida, o transformamos e aplicamos abordagens de aprendizado de máquina para construir modelos eficientes que podem prever a popularidade dos filmes." \cite{afzal2016} (tradução do autor)\par
        Entre os resultados obtidos, o autor destaca: "Depois de fazer a classificação, descobrimos que nossos melhores resultados são alcançados por meio de regressão logística. Os atributos que mais contribuíram para a informação são o metascore e o número de votos de cada filme, os Oscars conquistados pelos filmes e a quantidade de telas que o filme vai passar." \cite{afzal2016}\newline

        \textbf{Predição de bilheteria}\par
        Em relação à predição de bilheteria para um filme, Quader et al destacam a importância dos metadados no artigo "Performance evaluation of seven machine learning classification techniques for movie box office success prediction" ("Avaliação de desempenho de sete técnicas de classificação de aprendizado de máquina para previsão de sucesso de bilheteria de filmes", tradução nossa). Os autores buscam "realizar uma comparação de desempenho entre vários métodos de aprendizado de máquina. Escolhemos sete técnicas de aprendizado de máquina para esta comparação, como Support Vector Machine (SVM), Regressão Logística, Multilayer Perceptron Neural Network, Gaussian Naive Bayes, Random Forest, AdaBoost e Stochastic Gradient Descent (SGD). Todos esses métodos prevêem um valor aproximado de lucro líquido de um filme, analisando dados históricos de diferentes fontes como IMDb, Rotten Tomatoes, Box Office Mojo e Meta Critic." \cite{quader2017} (tradução do autor)\par
        Entre as conclusões, os autores citam elementos que podem facilitar ou dificultar a análise: "Se a condição econômica e política de um país não é estável, não importa o quão bem o filme seja feito, não haverá ninguém para assisti-lo. Portanto, incluir o PIB de um país como um atributo é uma boa opção para uma análise posterior. Também sugerimos analisar e incluir o número de público para análise. Podemos obter o número de audiência anual usando o total de ingressos vendidos em um determinado ano. Incluir esses atributos tornará a previsão mais precisa."

