{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Aprendizagem de máquina aplicada à previsão de premiações em metadados de cinema","metadata":{}},{"cell_type":"markdown","source":"Esse trabalho tem como objetivo investigar como os dados de orçamento, receita, data de lançamento, linguagens, país de produção e empresas produtoras, palavras-chave da trama, créditos de elenco e equipe influenciam nas chances de premiação no Oscar. Especificamente, objetiva-se:\n\n- detectar quais fatores são os mais preditivos com relação à chance de nomeação ou vitória de um filme no Oscar, e com qual grau de certeza é possível fazer essa previsão;\n- prever quais as categorias mais prováveis de premiação;\n- considerar dados adicionais que possam complementar a atividade preditiva;\n- analisar a importância individual dos fatores nas indicações e premiações;\n- extrapolar as conclusões, se possível, para fatores que influenciam e permitem o cálculo de chances de indicações e vitórias em outras premiações.","metadata":{}},{"cell_type":"markdown","source":"A metodologia para fazer essa investigação seguirá os seguintes passos:\n\n1. [utilização de histórico de metadados de filmes e indicações ao Oscar](#1) obtidos na plataforma Kaggle;\n2. [limpeza e tratamento dos dados](#2), verificando-se por dados faltantes, espúrios, e extremos indicados por meio de análises de distribuição;\n3. criação de um [arcabouço de análise exploratória](#3) em ambiente Python fazendo-se uso dos pacotes Pandas, Numpy, e Scikit Learn;\n4. criação de modelos de regressão para a chance de premiação, considerando-se diferentes algoritmos como árvores de decisão, regressão logística, support vector machines, random forest, redes neurais, dentre outros;\n5. avaliação comparativa dos resultados usando as métricas de mean squared error, root mean squared error, e mean absolute error;\n6. avaliação da importância de cada fator (metadado) baseando-se no feedback dos algoritmos testados;\n7. interpretação dos resultados para elaboração das conclusões com indicação das técnicas mais promissoras.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n## 1. Utilização de histórico de metadados e indicações ao Oscar do Kaggle","metadata":{}},{"cell_type":"code","source":"# importação das bibliotecas utilizadas\nimport json\nfrom difflib import SequenceMatcher\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nprint('Imports concluded')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T05:40:27.651360Z","iopub.execute_input":"2021-11-02T05:40:27.651635Z","iopub.status.idle":"2021-11-02T05:40:27.657044Z","shell.execute_reply.started":"2021-11-02T05:40:27.651607Z","shell.execute_reply":"2021-11-02T05:40:27.656130Z"},"trusted":true},"execution_count":272,"outputs":[]},{"cell_type":"code","source":"# Marcar como True para reproduzir as etapas mais lentas e verbosas do processo\nVERBOSE = False\n\nprint(f'VERBOSE: {VERBOSE}')","metadata":{"execution":{"iopub.status.busy":"2021-11-02T05:40:27.658360Z","iopub.execute_input":"2021-11-02T05:40:27.658837Z","iopub.status.idle":"2021-11-02T05:40:27.670506Z","shell.execute_reply.started":"2021-11-02T05:40:27.658809Z","shell.execute_reply":"2021-11-02T05:40:27.669775Z"},"trusted":true},"execution_count":273,"outputs":[]},{"cell_type":"code","source":"# carregando os filmes indicados ou vencedores do Oscar em um dataframe\n# e examinando as características do dataframe\noscar_nominations = pd.read_csv('/kaggle/input/the-oscar-award/the_oscar_award.csv')\n\noscar_nominations.info()\noscar_nominations.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T05:40:27.672416Z","iopub.execute_input":"2021-11-02T05:40:27.672704Z","iopub.status.idle":"2021-11-02T05:40:27.721105Z","shell.execute_reply.started":"2021-11-02T05:40:27.672667Z","shell.execute_reply":"2021-11-02T05:40:27.720259Z"},"trusted":true},"execution_count":274,"outputs":[]},{"cell_type":"code","source":"# A única coluna com itens faltantes é a coluna film.\n# Vamos explorar as linhas em que faltam esses dados para entender o porquê,\n# e em quais categorias isso está ocorrendo\nprint(oscar_nominations[oscar_nominations['film'].isnull()]['category'].unique())\noscar_nominations[oscar_nominations['film'].isnull()].head()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T05:40:27.722564Z","iopub.execute_input":"2021-11-02T05:40:27.722788Z","iopub.status.idle":"2021-11-02T05:40:27.738989Z","shell.execute_reply.started":"2021-11-02T05:40:27.722763Z","shell.execute_reply":"2021-11-02T05:40:27.738207Z"},"trusted":true},"execution_count":275,"outputs":[]},{"cell_type":"code","source":"# Alguns desses casos se tratam de prêmios honorários, humanitários e memoriais -\n# ou seja, não relacionados a filmes específicos. Podemos desconsiderar essas linhas\nrows_to_drop = oscar_nominations[\n    (oscar_nominations['category'] == 'HONORARY AWARD') |\n    (oscar_nominations['category'] == 'SPECIAL AWARD') |\n    (oscar_nominations['category'] == 'IRVING G. THALBERG MEMORIAL AWARD') |\n    (oscar_nominations['category'] == 'JEAN HERSHOLT HUMANITARIAN AWARD') |\n    (oscar_nominations['category'] == 'SPECIAL ACHIEVEMENT AWARD')\n].index\n\noscar_nominations = oscar_nominations.drop(rows_to_drop)\n\nprint(oscar_nominations[oscar_nominations['film'].isnull()]['category'].unique())\noscar_nominations[oscar_nominations['film'].isnull()].head()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T05:40:27.740334Z","iopub.execute_input":"2021-11-02T05:40:27.740854Z","iopub.status.idle":"2021-11-02T05:40:27.763958Z","shell.execute_reply.started":"2021-11-02T05:40:27.740823Z","shell.execute_reply":"2021-11-02T05:40:27.763252Z"},"trusted":true},"execution_count":276,"outputs":[]},{"cell_type":"code","source":"# As linhas restantes com dados faltantes na coluna filme são de categorias\n# que precisam necessariamente estar ligadas a um filme.\n\n# Para duas dessas categorias, ligadas a filmes estrangeiros, o nome do filme parece constar\n# na coluna 'name'\n\nfor row in oscar_nominations[\n    (oscar_nominations['category'] == 'SPECIAL FOREIGN LANGUAGE FILM AWARD') |\n    (oscar_nominations['category'] == 'HONORARY FOREIGN LANGUAGE FILM AWARD')\n].iterrows():\n    print(row[1][4])\n\n# em todos esses casos, com exceção do último, o nome do filme consta na coluna 'name',\n# seguido de hífen. Podemos aplicar a mesma regra para todos os casos, e transpor o nome do\n# filme para a coluna film\noscar_nominations['film'] = oscar_nominations.apply(\n    lambda x: x['name'].split('-')[0] if x['category'] in (\n        'SPECIAL FOREIGN LANGUAGE FILM AWARD', 'HONORARY FOREIGN LANGUAGE FILM AWARD'\n    )\n    else x['film'],\n    axis=1\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T05:40:27.765650Z","iopub.execute_input":"2021-11-02T05:40:27.765956Z","iopub.status.idle":"2021-11-02T05:40:27.902494Z","shell.execute_reply.started":"2021-11-02T05:40:27.765925Z","shell.execute_reply":"2021-11-02T05:40:27.901618Z"},"trusted":true},"execution_count":277,"outputs":[]},{"cell_type":"code","source":"# Com os dados dessas categorias corrigidos,\n# é hora de checar os dados que ainda são faltantes\nprint(oscar_nominations[oscar_nominations['film'].isnull()]['category'].unique())\noscar_nominations[oscar_nominations['film'].isnull()].head()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T05:40:27.903978Z","iopub.execute_input":"2021-11-02T05:40:27.904354Z","iopub.status.idle":"2021-11-02T05:40:27.918821Z","shell.execute_reply.started":"2021-11-02T05:40:27.904325Z","shell.execute_reply":"2021-11-02T05:40:27.918283Z"},"trusted":true},"execution_count":278,"outputs":[]},{"cell_type":"code","source":"# Outras linhas com dados faltantes na coluna 'film' são de obtenção difícil ou imprecisa:\n# um assistente de direção, por exemplo, pode ter tido mais de um filme lançado num mesmo\n# ano, o que faria a checagem dos dados restantes muito trabalhosa.\n# Essas colunas serão ignoradas.\nrows_to_drop = oscar_nominations[\n    (\n        (oscar_nominations['category'] == 'ENGINEERING EFFECTS') |\n        (oscar_nominations['category'] == 'WRITING (Title Writing)') |\n        (oscar_nominations['category'] == 'SOUND RECORDING') |\n        (oscar_nominations['category'] == 'ASSISTANT DIRECTOR')\n    ) & (oscar_nominations['film'].isnull())\n].index\n\noscar_nominations = oscar_nominations.drop(rows_to_drop)\n\noscar_nominations.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T05:40:27.919934Z","iopub.execute_input":"2021-11-02T05:40:27.920362Z","iopub.status.idle":"2021-11-02T05:40:27.941582Z","shell.execute_reply.started":"2021-11-02T05:40:27.920333Z","shell.execute_reply":"2021-11-02T05:40:27.940769Z"},"trusted":true},"execution_count":279,"outputs":[]},{"cell_type":"code","source":"# Um fato que pode ser observado analisando esses dados restantes é que algumas das\n# categorias tiveram mudanças de nomes - como foi o caso na premiação de filme de língua\n# estrangeira. Já outras categorias desapareceram da premiação (\"melhor filme em preto e\n# branco\") ou foram incluídas.\n\n# A categoria mais recente incluída na premiação é a de melhor filme de animação, criada em\n# 2002. Por isso, iremos desconsiderar filmes anteriores a essa data.\n\nrows_to_drop = oscar_nominations[(oscar_nominations['year_ceremony'] < 2002)].index\noscar_nominations = oscar_nominations.drop(rows_to_drop)\n\n# Iremos desconsiderar ainda a premiação de edição de som (sound editing),\n# que foi descontinuada em 2019, a única removida após o ano de 2002.\nrows_to_drop = oscar_nominations[(oscar_nominations['category'] == 'SOUND EDITING')].index\noscar_nominations = oscar_nominations.drop(rows_to_drop)\n\nlist(oscar_nominations['category'].unique())","metadata":{"execution":{"iopub.status.busy":"2021-11-02T05:40:27.942827Z","iopub.execute_input":"2021-11-02T05:40:27.943056Z","iopub.status.idle":"2021-11-02T05:40:27.960685Z","shell.execute_reply.started":"2021-11-02T05:40:27.943032Z","shell.execute_reply":"2021-11-02T05:40:27.959704Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"code","source":"# Algumas dessas categorias também precisaram de consolidação, já que seus nomes\n# aparecem de formas diferentes. Foram utilizados os nomes mais recentes.\n\ncategory_renaming = {\n    'FOREIGN LANGUAGE FILM': 'INTERNATIONAL FEATURE FILM',\n    'ART DIRECTION': 'PRODUCTION DESIGN',\n    'WRITING (Screenplay Based on Material Previously Produced or Published)': 'WRITING (Adapted Screenplay)',\n    'WRITING (Screenplay Written Directly for the Screen)': 'WRITING (Original Screenplay)',\n    'SOUND MIXING': 'SOUND',\n    'MAKEUP': 'MAKEUP AND HAIRSTYLING',\n}\n\noscar_nominations['category'] = oscar_nominations.apply(\n    lambda x: category_renaming[x['category']]\n    if x['category'] in category_renaming\n    else x['category'],\n    axis=1\n)\n\n# Checando que agora temos as 23 categorias atuais do Oscar\nlist(oscar_nominations['category'].unique())","metadata":{"execution":{"iopub.status.busy":"2021-11-02T05:40:27.962352Z","iopub.execute_input":"2021-11-02T05:40:27.962723Z","iopub.status.idle":"2021-11-02T05:40:28.004536Z","shell.execute_reply.started":"2021-11-02T05:40:27.962682Z","shell.execute_reply":"2021-11-02T05:40:28.003587Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"code","source":"# Agora precisamos integrar os esquemas dos datasets do Oscar e de metadados de filmes.\n\n# carregando os metadados de todos os filmes\nmovies_metadata = pd.read_csv(\n    '/kaggle/input/the-movies-dataset/movies_metadata.csv',\n)\n\n# converter coluna release_date para datetime\nmovies_metadata['release_date'] = movies_metadata['release_date'].apply(\n    lambda x: pd.to_datetime(x, errors='coerce'),\n)\n\n# examinando as características do dataframe\nmovies_metadata.info()\nmovies_metadata.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-02T05:40:28.006130Z","iopub.execute_input":"2021-11-02T05:40:28.006632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n## 2. Limpeza e tratamento dos dados","metadata":{}},{"cell_type":"code","source":"# Tratamentos de formato de colunas\ndef convert_to_bool(x):\n    if isinstance(x, bool):\n        return x\n    elif x in [0, 1]:\n        return bool(x)\n    elif x == 'False':\n        return False\n    elif x == 'True':\n        return True\n    else:\n        return False\n\ndef convert_to_float(x):\n    if isinstance(x, float) or isinstance(x, int):\n        return x\n    elif isinstance(x, str) and x.isnumeric():\n        return float(x)\n    else:\n        return 0\n\n# Convertendo a coluna adult para booleano\nfor column in [\n    'adult',\n    'video',\n]:\n    movies_metadata[column] = movies_metadata[column].apply(convert_to_bool)\n    print(f'Converted column {column} on movies dataset')\n\n# Garantindo valores numéricos para as colunas budget, popularity\nfor column in [\n    'budget',\n    'popularity',\n]:\n    movies_metadata[column] = movies_metadata[column].apply(convert_to_float)\n    print(f'Converted column {column} on movies dataset')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Há títulos originais erroneamente em formato json na tabela. Vamos analisá-los\njson_titles = [\n    title for title in movies_metadata['original_title'].values if not isinstance(title, float) and \"{\" in title\n]\n\nmovies_to_adjust = movies_metadata.loc[\n    movies_metadata['original_title'].isin(json_titles)\n]\n\nmovies_to_adjust","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Essas três instâncias parecem ter o mesmo problema: colunas desalinhadas pela falta de algum valor.\n# É possível que estejam na seguinte ordem:\n# overview, popularity, poster_path, production_companies, production_countries, release_date, revenue, runtime, spoken_languages, 'status', 'tagline', 'title', 'video', 'vote_average', 'vote_count', 'adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id', 'imdb_id', 'original_language', 'original_title', \n# na impossibilidade de confirmar exatamente quais dados pertencem a quais colunas, vamos eliminá-los\nmovies_metadata.drop(movies_to_adjust.index, inplace=True)\nprint('Dropped broken instances')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confirmando a exclusão\njson_titles = [\n    title for title in movies_metadata['original_title'].values if not isinstance(title, float) and \"{\" in title\n]\n\nmovies_to_adjust = movies_metadata.loc[\n    movies_metadata['original_title'].isin(json_titles)\n]\n\nmovies_to_adjust","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adicionando uma coluna com o ano de lançamento do filme, que será útil em outras análises\nmovies_metadata['release_year'] = movies_metadata['release_date'].apply(lambda x: x.year)\nmovies_metadata['release_year'].describe()\n\ndef days_since_start_of_year(release_date):\n    start_of_year = release_date.replace(day=1, month=1)\n    days = (release_date - start_of_year).days\n    if isinstance(days, int):\n        return days\n    else:\n        return 0\n\n# Convertendo release_date em um inteiro release_day, que representa \n# o número de dias desde o começo do ano até o lançamento\nmovies_metadata['release_day'] = movies_metadata['release_date'].apply(days_since_start_of_year)\n\n# Conferindo a transformação em release_day\nmovies_metadata[['title', 'release_date', 'release_day']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removendo a coluna release_date\nmovies_metadata.drop('release_date', 1, inplace=True)\nprint('Dropped column release_date')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Precisamos retirar os filmes pós 2017 do dataset do oscar, já que não estão presentes no The Movie Dataset\nrows_to_drop = oscar_nominations[(oscar_nominations['year_film'] > 2017)].index\noscar_nominations = oscar_nominations.drop(rows_to_drop)\n\noscar_nominations['year_film'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Também precisamos retirar os filmes pré-2001 e pós 2017 que existam no The Movie Dataset\nrows_to_drop = movies_metadata[\n    (movies_metadata['release_year'] < 2001) |\n    (movies_metadata['release_year'] > 2017)\n].index\nmovies_metadata = movies_metadata.drop(rows_to_drop)\n\nmovies_metadata['release_year'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Criando uma função de normalização de nomes para comparação entre os dois datasets\n# Essa função será utilizada para evitar que nomes idênticos não sejam encontrados por conta de\n# pontuação, capitalização ou caracteres especiais encontrados em exemplos de nomes de filmes\ndef normalize(name):\n    normalized_name = name\n    try:\n        normalized_name = normalized_name.lower()\n\n        for character in [\n            ':', '!', '?', ' -', '- ', '-', '/', '.', '·', ',', '\"', '\\u200e'\n        ]:\n            normalized_name = normalized_name.replace(character, '')\n\n        for character_to_replace, replacement in {\n            'ž': 'z',\n            'ń': 'n',\n            '&': 'and',\n            '...': ' ',\n        }.items():\n            if character_to_replace in normalized_name:\n                normalized_name = normalized_name.replace(character_to_replace, replacement)\n\n        normalized_name = normalized_name.strip()\n                \n    except:\n        pass\n\n    return normalized_name\n\nfor column in [\n    'title', 'original_title'\n]:\n    movies_metadata[f'normalized_{column}'] = movies_metadata[column].apply(normalize)\n    print(f'Normalized column {column} in the movies dataset')\n    \nfor column in [\n    'film'\n]:\n    oscar_nominations[f'normalized_{column}'] = oscar_nominations[column].apply(normalize)\n    print(f'Normalized column {column} in the Oscar dataset')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checar filmes do Oscar que não estão no dataset de metadados,\n# considerando títulos exatos e dando margem de +- 2 anos de diferença\n# entre as datas existentes nas tabelas\nnot_found_movies = []\nfound_movies = []\n\ntotal_nominations = len(oscar_nominations)\n\ni = 0\nfor nomination in oscar_nominations.iterrows():\n    i += 1\n    print(f'Analysing nomination {i} of {total_nominations}', end='\\r')\n    \n    data = nomination[1]\n    normalized_film = data['normalized_film']\n    year_film = data['year_film']\n    \n    found_title = None\n    \n    # Checando nos títulos em inglês\n    if len(\n        movies_metadata.loc[\n            (movies_metadata['normalized_title'] == normalized_film) & \n            (movies_metadata['release_year'] >= year_film - 2) &\n            (movies_metadata['release_year'] <= year_film + 2)\n        ]\n    ):\n        found_title = normalized_film\n\n    # Checando nos títulos originais\n    elif len(\n        movies_metadata.loc[\n            (movies_metadata['normalized_original_title'] == normalized_film) & \n            (movies_metadata['release_year'] >= year_film - 2) &\n            (movies_metadata['release_year'] <= year_film + 2)\n        ]\n    ):\n        # separar título em inglês\n        found_title = movies_metadata.loc[\n            (movies_metadata['normalized_original_title'] == normalized_film) & \n            (movies_metadata['release_year'] >= year_film - 2) &\n            (movies_metadata['release_year'] <= year_film + 2)\n        ]['normalized_title'].values[0]\n    \n    # Se não encontrado, considerar caso especial: filmes com os dois títulos no nome,\n    # separados por parênteses, \"'s\" ou outros caracteres especiais\n    else:\n        titles = [\n            title.strip() for title in\n            normalized_film.replace(\"'s\", '*****').replace('(', '*****').replace(')', '*****').split('*****')\n            if title\n        ]\n        \n        for title in titles:\n            # título parcial encontrado na coluna normalized_title\n            if len(\n                movies_metadata.loc[\n                    (movies_metadata['normalized_title'] == title) & \n                    (movies_metadata['release_year'] >= year_film - 2) &\n                    (movies_metadata['release_year'] <= year_film + 2)\n                ]\n            ):\n                found_title = title\n            \n            # título parcial encontrado na coluna normalized_original_title\n            elif len(\n                movies_metadata.loc[\n                    (movies_metadata['normalized_original_title'] == title) & \n                    (movies_metadata['release_year'] >= year_film - 2) &\n                    (movies_metadata['release_year'] <= year_film + 2)\n                ]\n            ):\n                found_title = movies_metadata.loc[\n                    (movies_metadata['normalized_original_title'] == title) & \n                    (movies_metadata['release_year'] >= year_film - 2) &\n                    (movies_metadata['release_year'] <= year_film + 2)\n                ]['normalized_title'].values[0]\n                \n            \n    if found_title:\n        found_movies.append((found_title, year_film))\n\n        found_year = movies_metadata.loc[\n            (movies_metadata['normalized_title'] == found_title) & \n            (movies_metadata['release_year'] >= year_film - 2) &\n            (movies_metadata['release_year'] <= year_film + 2)\n        ]['release_year'].values[0]\n        \n        # se o título encontrado é diferente do presente no dataset dos Oscars, atualizar o dataset\n        if found_title != normalized_film:            \n            oscar_nominations.loc[\n                (oscar_nominations['normalized_film'] == normalized_film) & \n                (oscar_nominations['year_film'] == year_film),\n                'normalized_film'\n            ] = found_title\n        \n        # se o ano encontrado é diferente do presente no dataset dos Oscars, atualizar o dataset\n        if found_year != year_film:            \n            oscar_nominations.loc[\n                (oscar_nominations['normalized_film'] == normalized_film) & \n                (oscar_nominations['year_film'] == year_film),\n                'year_film'\n            ] = found_year\n\n    else:\n        not_found_movies.append((normalized_film, year_film))\n    \n        \nfound_movies = list(set(found_movies))\nprint('\\n\\nFound', len(found_movies), 'movies')\n\nnot_found_movies = list(set(not_found_movies))\nprint('Did not find', len(not_found_movies), 'movies')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checar caso a caso filmes que podem estar com nomes levemente diferentes,\n# (ou com anos de lançamento diferentes) em cada um dos dois datasets,\n# realizando uma análise de similaridade entre os títulos normalizados\n# e considerando até dois anos de margem de erro para mais ou para menos\n\ndef similarity(a, b):\n    try:\n        return SequenceMatcher(None, a, b).ratio()\n    except:\n        return 0\n\n\ni = 0\ntotal = len(not_found_movies)\npossibly_found = {}\n\nif not VERBOSE:\n    print('Skipping')\nelse:\n    for oscar_title, year_film in not_found_movies:\n        i += 1\n        print(f'Analysing not found movie {i} of {total}', end=\"\\r\")\n        best_match = 0\n\n        for movie in movies_metadata.iterrows():\n            data = movie[1]\n            normalized_title = data['normalized_title']\n            normalized_original_title = data['normalized_original_title']\n            release_year = data['release_year']\n\n            # análise 1 - similaridade com o título em inglês\n            normalized_title_similarity = similarity(oscar_title, normalized_title)\n            if (normalized_title_similarity > best_match) and (release_year - 2 <= year_film <= release_year + 2):\n                best_match = normalized_title_similarity\n                possibly_found[oscar_title, year_film] = (\n                    'normalized_title',\n                    normalized_title,\n                    release_year,\n                    normalized_title_similarity,\n                )\n\n            # análise 2 - similaridade com o título original\n            normalized_original_title_similarity = similarity(oscar_title, normalized_original_title)\n            if (normalized_original_title_similarity > best_match) and (release_year - 2 <= year_film <= release_year + 2):\n                best_match = normalized_original_title_similarity\n                possibly_found[oscar_title, year_film] = (\n                    'normalized_original_title',\n                    normalized_original_title,\n                    release_year,\n                    normalized_original_title_similarity,\n                )\n\n    possibly_found\n    \n    # Salvar possibly_found em arquivo - sem ordenação\n    with open('possibly_found', 'w') as file:\n        file.write(str(possibly_found))\n\n    possibly_found_formatted = sorted(\n        [\n            (title_oscar, oscar_year, title_field, title_metadata, metadata_year, title_similarity)\n            for (title_oscar, oscar_year), (title_field, title_metadata, metadata_year, title_similarity)\n            in possibly_found.items()\n        ],\n        key=lambda x: x[4]\n    )\n\n    print('Not found movies:', possibly_found_formatted, end='\\n\\n')\n\n    # Salvar possibly_found em arquivo - com ordenação\n    with open('possibly_found_formatted', 'w') as file:\n        file.write(str(possibly_found_formatted))\n        print('file created')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Títulos equivalentes que podem ser reconhecidos nas duas listas a partir do arquivo gerado:\nmovies_to_rename = {\n    (\"glen campbelli'll be me\", 2014): ('normalized_title', \"glen campbell i'll be me\", 2014.0, 0.9787234042553191),\n    ('mt head', 2002): ('normalized_title', 'mount head', 2002.0, 0.8235294117647058),\n    ('the story of the weeping camel', 2004): ('normalized_title', 'the weeping camel', 2003.0, 0.723404255319149),\n    ('the lady and the reaper (la dama y la muerte)', 2009): ('normalized_title', 'the lady and the reaper', 2009.0, 0.6764705882352942),\n    ('harry potter and the sorcerer\\'s stone', 2001): ('normalized_title', 'harry potter and the philosopher\\'s stone', 2001.0, 0.8533333333333334),\n    ('wardance', 2007): ('normalized_title', 'war dance', 2007.0, 0.9411764705882353),\n    ('wallace and gromit in the curse of the wererabbit', 2005): ('normalized_title', 'the curse of the wererabbit', 2005.0, 0.7105263157894737),\n    ('the lady in number 6 music saved my life', 2013): ('normalized_title', 'the lady in number 6', 2013.0, 0.6666666666666666),\n    ('5 broken cameras', 2012): ('normalized_title', 'five broken cameras', 2011.0, 0.8571428571428571),\n    (\"precious based on the novel 'push' by sapphire\", 2009): ('normalized_title', 'precious', 2009.0, 0.2962962962962963),\n    ('birdman or (the unexpected virtue of ignorance)', 2014): ('normalized_title', 'birdman', 2014.0, 0.25925925925925924),\n}\n\n# padronizar a tabela do Oscar a partir dos dados da tabela de metadados\nfor oscar_movie, metadata_movie in movies_to_rename.items():\n    oscar_title = oscar_movie[0]\n    oscar_year = oscar_movie[1]\n\n    metadata_title = metadata_movie[1]\n    metadata_year = metadata_movie[2]\n    \n    print(f'Renaming movie \"{oscar_title}\" ({oscar_year}) to \"{metadata_title}\" ({metadata_year})')\n    \n    oscar_nominations.loc[\n        (oscar_nominations['normalized_film'] == oscar_title) & \n        (oscar_nominations['year_film'] == oscar_year),\n        ['normalized_film', 'year_film']\n    ] = metadata_title, metadata_year","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finalmente as duas tabelas estão prontas para serem integradas\n# Vamos usar one-hot enconding e utilizar abreviações para os nomes das categorias\n\nCATEGORY_CODES = {\n    'ACTOR IN A LEADING ROLE': 'leading_actor',\n    'ACTOR IN A SUPPORTING ROLE': 'supporting_actor',\n    'ACTRESS IN A LEADING ROLE': 'leading_actress',\n    'ACTRESS IN A SUPPORTING ROLE': 'supporting_actress',\n    'ANIMATED FEATURE FILM': 'animated_feature',\n    'PRODUCTION DESIGN': 'production_design',\n    'CINEMATOGRAPHY': 'cinematography',\n    'COSTUME DESIGN': 'costume_design',\n    'DIRECTING': 'directing',\n    'DOCUMENTARY (Feature)': 'documentary_feature',\n    'DOCUMENTARY (Short Subject)': 'documentary_short subject',\n    'FILM EDITING': 'editing',\n    'INTERNATIONAL FEATURE FILM': 'international_feature',\n    'MAKEUP AND HAIRSTYLING': 'makeup',\n    'MUSIC (Original Score)': 'original_score',\n    'MUSIC (Original Song)': 'original_song',\n    'BEST PICTURE': 'best_picture',\n    'SHORT FILM (Animated)': 'animated_short',\n    'SHORT FILM (Live Action)': 'live_action_short',\n    'SOUND': 'sound',\n    'VISUAL EFFECTS': 'visual_effects',\n    'WRITING (Adapted Screenplay)': 'writing_adapted',\n    'WRITING (Original Screenplay)': 'writing_original',\n}\n\ncategory_slugs = CATEGORY_CODES.values()\n\n# Criando as colunas para indicação e vitória em cada categoria\nfor category in category_slugs:    \n    movies_metadata[f'nominated_{category}'] = 0\n    movies_metadata[f'won_{category}'] = 0\n    \nmovies_metadata['year_ceremony'] = None\n\ni = 0\nfound_movies = []\nfound_nominations = 0\nfor index, nomination_data in oscar_nominations.iterrows():\n    i += 1\n    print(f'Analysing nomination {i} of {total_nominations}', end='\\r')\n    title = nomination_data['normalized_film']\n    year_film = nomination_data['year_film']\n    year_ceremony = nomination_data['year_ceremony']\n\n    category = nomination_data['category']\n    category_code = CATEGORY_CODES[category]\n    winner = nomination_data['winner']\n\n    correlated_movies = movies_metadata.loc[\n        (movies_metadata['normalized_title'] == title) & \n        (movies_metadata['release_year'] == year_film),\n        [f'nominated_{category_code}', f'won_{category_code}', 'year_ceremony']\n    ]\n    \n    if len(correlated_movies) == 1:\n        found_nominations += 1\n        found_movies.append((title, year_film))\n        movies_metadata.loc[\n            (movies_metadata['normalized_title'] == title) & \n            (movies_metadata['release_year'] == year_film),\n            [f'nominated_{category_code}', f'won_{category_code}', 'year_ceremony']\n        ] = 1, winner, year_ceremony","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# teste 1 - validando filmes vencedores do Oscar de melhor filme diretamente na tabela de metadados\nmovies_metadata[movies_metadata['won_best_picture'] == 1][\n    ['title', 'nominated_best_picture', 'year_ceremony']\n].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# teste 2 - validando filmes indicados ao Oscar em 2002\nmovies_metadata[\n    (movies_metadata['nominated_best_picture'] == 1) &\n    (movies_metadata['year_ceremony'] == 2002)\n][\n    ['title', 'nominated_best_picture', 'won_best_picture', 'year_ceremony']\n].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checando o número de gêneros existentes, e o número de ocorrências de cada um\nall_genres = {}\nfor genres in movies_metadata[movies_metadata['genres'].notna()]['genres'].values:\n    genres = json.loads(genres.replace(\"'\", '\"'))\n\n    for genre in genres:\n        name = genre['name']\n        if name.lower() not in all_genres:\n            all_genres[name.lower()] = 0\n            \n        all_genres[name.lower()] += 1\n            \nall_genres","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# alguns gêneros apresentam apenas uma ocorrência - serão eliminados\nvalid_genres = []\nfor genre_name, occurrences in all_genres.items():\n    if occurrences > 1:\n        valid_genres.append(genre_name.replace(' ', '_'))\n        \nvalid_genres","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convertendo os códigos de gênero em colunas usando one-hot encoding:\nfor genre in valid_genres:\n    movies_metadata[f'genre_{genre}'] = 0 \n\ntotal_movies = len(movies_metadata)\ni = 0\n\nfor movie in movies_metadata.iterrows():\n    i += 1\n    print(f'Analysing movie {i} of {total_movies}', end='\\r')\n    index = movie[0]\n    genres = movie[1]['genres']\n    \n    genres = json.loads(genres.replace(\"'\", '\"'))\n    for genre in genres:\n        name = genre['name'].lower().replace(' ', '_')\n        if name in valid_genres:\n            movies_metadata.loc[\n                index,\n                f'genre_{name}'\n            ] = 1\n            \nmovies_metadata.drop('genres', 1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# analisando manualmente filmes de um gênero para conferir\nanimation_movies = movies_metadata[movies_metadata['genre_animation'] == 1]['title'].values\n\nanimation_movies, len(animation_movies)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checando o número de países de produção existentes, e o número de ocorrências de cada um\nall_countries = {}\nfor countries in movies_metadata[movies_metadata['production_countries'].notna()]['production_countries'].values:\n    countries = json.loads(countries.replace(\"D'I\", 'DI').replace(\"People's\", \"Peoples\").replace(\"'\", '\"'))\n\n    if isinstance(countries, list):\n        for country in countries:\n            code = country['iso_3166_1']\n            if code not in all_countries:\n                all_countries[code] = 0\n\n            all_countries[code] += 1\n        \n    \nprint(f'{len(all_countries)} countries found')\n\n# convertendo os países de produção em colunas usando one-hot encoding:\nfor country in all_countries:\n    movies_metadata[f'country_{country}'] = 0 \n\ntotal_movies = len(movies_metadata)\ni = 0\n\nfor movie in movies_metadata.iterrows():\n    i += 1\n    print(f'Adding country columns to movie {i} of {total_movies}', end='\\r')\n    index = movie[0]\n    countries = movie[1]['production_countries']\n    \n    if isinstance(countries, str):\n        countries = json.loads(countries.replace(\"D'I\", 'DI').replace(\"People's\", \"Peoples\").replace(\"'\", '\"'))\n        if isinstance(countries, list):\n            for country in countries:\n                code = country['iso_3166_1']\n                movies_metadata.loc[\n                    index,\n                    f'country_{code}'\n                ] = 1\n            \nmovies_metadata.drop('production_countries', 1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checando o número de linguagens existentes, e o número de ocorrências de cada uma\nall_languages = {}\nfor languages in movies_metadata[movies_metadata['spoken_languages'].notna()]['spoken_languages'].values:\n    languages = json.loads(languages.replace('\\\\x9akai', '').replace(\"'\", '\"'))\n        \n    if isinstance(languages, list):\n        for language in languages:\n            code = language['iso_639_1'].upper()\n            if code not in all_languages:\n                all_languages[code] = 0\n\n            all_languages[code] += 1\n\n\nprint(f'{len(all_languages)} languages found')\n\n# convertendo as linguagens em colunas usando one-hot encoding:\nfor language in all_languages:\n    movies_metadata[f'spoken_language_{language}'] = 0\n\ntotal_movies = len(movies_metadata)\ni = 0\n\nfor movie in movies_metadata.iterrows():\n    i += 1\n    print(f'Adding language columns to movie {i} of {total_movies}', end='\\r')\n    index = movie[0]\n    languages = movie[1]['spoken_languages']\n\n    if isinstance(languages, str):\n        languages = json.loads(languages.replace('\\\\x9akai', '').replace(\"'\", '\"'))\n        if isinstance(languages, list):\n            for language in languages:\n                code = language['iso_639_1'].upper()\n                movies_metadata.loc[\n                    index,\n                    f'spoken_language_{code}'\n                ] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# conferindo manualmente os valores para cada linguagem falada\nlanguage_columns = [f'spoken_language_{language}' for language in all_languages]\nmovies_metadata[language_columns].sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# repetindo o processo para a coluna de linguagem original\nall_languages = {}\nfor language in movies_metadata[movies_metadata['original_language'].notna()]['original_language'].values:\n    if isinstance(language, str) and not language.replace('.', '').isnumeric():\n        language = language.upper()\n        if language not in all_languages:\n            all_languages[language] = 0\n        all_languages[language] += 1\n\nprint(f'{len(all_languages)} languages found')\n\n# convertendo as linguagens em colunas usando one-hot encoding:\nfor language in all_languages:\n    movies_metadata[f'original_language_{language}'] = 0\n\ntotal_movies = len(movies_metadata)\ni = 0\n\nfor movie in movies_metadata.iterrows():\n    i += 1\n    print(f'Adding language columns to movie {i} of {total_movies}', end='\\r')\n    index = movie[0]\n    language = movie[1]['original_language']\n\n    if isinstance(language, str) and not language.replace('.', '').isnumeric():\n        language = language.upper()\n        movies_metadata.loc[\n            index,\n            f'original_language_{language}'\n        ] = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# conferindo manualmente os valores para a coluna linguagem original\nlanguage_columns = [f'original_language_{language}' for language in all_languages]\nmovies_metadata[language_columns].sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analisando a quantidade de empresas produtoras\nall_companies = {}\ni = 0\nfor companies in movies_metadata[movies_metadata['production_companies'].notna()]['production_companies'].values:\n    i += 1\n    print(f'Analysing movie {i} of {total_movies}. Number of companies: {len(all_companies)}', end='\\r')\n\n    try:\n        # evitando caracteres problema em nomes estrangeiros\n        companies = companies.replace(\"'\", '\"')\n        companies = json.loads(companies)\n        for company in companies:\n            name = company['name']\n            if name.lower() not in all_companies:\n                all_companies[name.lower()] = 0\n\n            all_companies[name.lower()] += 1\n            \n    except Exception as e:\n        pass\n\n# mesmo ignorando nomes problemáticos de produtoras, temos mais de 22 mil empresas listadas.\n# a análise desse item poderia trazer informações relevantes, mas seria extremamente problemática\n\n# removendo a coluna \nmovies_metadata.drop('production_companies', 1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checando as transformações\nfor column in ['adult', 'budget', 'popularity']:\n    print('Column', column, 'types:', movies_metadata[column].apply(lambda x: type(x)).unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ainda há filmes sem valor na coluna título.\ntitles_to_correct = movies_metadata.loc[\n    movies_metadata['title'].apply(type) == float,\n    ['title', 'original_title']\n]\nprint(titles_to_correct)\n\n# vamos aplicar a esses filmes \n# o título existente na coluna de título original\nmovies_metadata.loc[titles_to_correct.index, 'title'] = titles_to_correct['original_title']\n\n\nmovies_metadata.loc[titles_to_correct.index, ['title', 'original_title']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Última análise e tratamento necessária: coluna 'status'\nprint(movies_metadata['status'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Há filmes marcados no dataset como especulados, em produção... \n# Mas apenas podem ser considerados ao Oscar filmes que efetivamente tenham sido lançados\n# Vamos checar se algum dos filmes especulados, em produção, etc, recebeu alguma indicação ou prêmio\n\nunreleased = movies_metadata[\n    movies_metadata['status'] != 'Released'\n]\nprint(f'{len(unreleased)} movies marked as unreleased', '\\n')\n\nnomination_columns = [\n    column for column in movies_metadata.columns if 'nominated_' in column\n]\naward_columns = [\n    column for column in movies_metadata.columns if 'won_' in column\n]\n\nnominated = []\nfor index, movie in unreleased.iterrows():\n    nominations = []\n    awards = []\n\n    for column in nomination_columns:\n        if movie[column]:\n            nominations.append(column)\n    for column in award_columns:\n        if movie[column]:\n            awards.append(column)\n            \n    if nominations or awards:\n        nominated.append((movie['title'], movie['release_year']))\n        print(f\"{movie['title']} ({int(movie['release_year'])})\")\n        print('Nominations:', ','.join(nominations))\n        print('Awards:', ','.join(awards), '\\n')\n\nunreleased_to_drop = [\n    index for index, movie in unreleased.iterrows()\n    if (movie['title'], movie['release_year']) not in nominated\n]\n\nmovies_metadata.drop(unreleased_to_drop, inplace=True)\n\nprint(f'{len(unreleased_to_drop)} unreleased movies dropped')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confirmando a exclusão\nunreleased = movies_metadata[\n    movies_metadata['status'] != 'Released'\n]\nprint(f'{len(unreleased)} movies marked as unreleased')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Não serão interpretadas as colunas a seguir,\n# por não dizerem respeito ao problema em questão,\n# ou por não serem quantificáveis para a análise\nfor column in [\n    'belongs_to_collection',\n    'homepage',\n    'imdb_id',\n    'id',\n    'original_title',\n    'overview',\n    'poster_path',\n    'tagline',\n    'original_language',\n    'spoken_languages',\n    'normalized_title',\n    'normalized_original_title',\n    'status',\n]:\n    movies_metadata.drop(column, 1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preencher campos faltantes\nmovies_metadata.fillna(value=0, inplace=True)\nprint('Filled n/a values')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mover para o índice da tabela os campos de identificação do filme\nmovies_metadata.set_index(['release_year', 'title'], inplace=True)\nmovies_metadata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adicionando colunas 'atalho' para as classes-alvo:\n# uma que indica se o filme obteve ao menos uma indicação\n# e outra que indica se o filme obteve ao menos uma vitória\ncolumns_nominations = [\n    column for column in movies_metadata.columns \n    if 'nominated_' in column\n]\ncolumns_wins = [\n    column for column in movies_metadata.columns \n    if 'won_' in column\n]\n\nmovies_metadata['nominated_at_least_once'] = movies_metadata[columns_nominations].any(axis=1)\nmovies_metadata['won_at_least_once'] = movies_metadata[columns_wins].any(axis=1)\n\n# Conferindo: filmes que receberam pelo menos uma indicação e não ganharam nenhum prêmio\nmovies_metadata[\n    (movies_metadata['nominated_at_least_once'] == True) &\n    (movies_metadata['won_at_least_once'] == False) \n][['nominated_at_least_once', 'won_at_least_once']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n## 3. Análise Exploratória","metadata":{}},{"cell_type":"code","source":"# Esquema após as transformações\nmovies_metadata.info(verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Conferindo manualmente as primeiras instâncias\nmovies_metadata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculando as correlações entre as colunas\ncorrs = movies_metadata.corr().abs()\nsorted_corrs = corrs.unstack().sort_values(kind=\"quicksort\", ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# número de correlações para cada threshold testado\nCORR_THRESHOLDS = [1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n\n# função que retorna as maiores correlações únicas entre duas colunas.\n# Ignora a correlação entre países de produção, idiomas, e a correlação\n# (previsível) entre indicações e vitórias numa mesma categoria\ndef large_corrs(sorted_corrs, threshold, include_nominations_and_victories=True):\n    corrs = {}\n    for (a, b), row in sorted_corrs.iteritems():\n        if a != b and row > threshold and \\\n            (a, b) not in corrs and \\\n            (b, a) not in corrs and \\\n            not ('country_' in a or 'country_' in b) and \\\n            not ('spoken_language' in a or 'spoken_language' in b) and \\\n            not ('original_language' in a or 'original_language' in b) and \\\n            not (a.replace('won_', '').replace('nominated_', '') == b.replace('won_', '').replace('nominated_', '')):\n            corrs[(a,b)] = row\n\n    if include_nominations_and_victories:\n        result = corrs\n    else:\n        result = {}\n        for corr, value in corrs.items():\n            if 'nominated_' not in corr[0] and 'nominated_' not in corr[1] and \\\n                'won_' not in corr[0] and 'won_' not in corr[1]:\n                result[corr] = value\n    \n    return result\n\nnumber_of_corrs = []\n\nfor threshold in CORR_THRESHOLDS:\n    corrs = large_corrs(sorted_corrs, threshold)\n    number_of_corrs.append(len(corrs))\n    \nplt.plot(CORR_THRESHOLDS, number_of_corrs)\nplt.xlabel('Correlação mínima definida')\nplt.ylabel('Número de correlações encontradas')\nplt.title('Correlações encontradas x correlação mínima (inclui indicações)')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# escolhendo um threshold arbitrário, para imprimir apenas as maiores correlações\nCORR_THRESHOLD = 0.4\n        \ncorrs = large_corrs(sorted_corrs, CORR_THRESHOLD)\n\nprint(f'{len(corrs)} correlations found larger than {CORR_THRESHOLD} (includes nominations)')\ncorrs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Análise: lista de filmes ganhadores do Oscar de Efeitos Visuais\nmovies_metadata[movies_metadata['won_visual_effects'] == True].index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# contagem das colunas que mais aparecem nas correlações, incluindo indicações\n# foram excluídas as colunas de vitória em uma categoria\n# ('won_****'), que não serão usadas como atributo\ncounts = {}\nfor a, b in corrs:\n    counts[a] = counts.get(a, 0) + 1\n    counts[b] = counts.get(b, 0) + 1\n\nsorted_counts = sorted(\n    [\n        (column, value) for column, value in counts.items()\n        if 'won_' not in column\n    ],\n    key=lambda x: x[1],\n)\nsorted_dict = {\n    column: value for column, value in sorted_counts\n}\n\nplt.barh(list(sorted_dict.keys()), list(sorted_dict.values()))\nplt.title('Atributos mais presentes nas maiores correlações (incluindo indicações)')\nplt.ylabel('Atributo')\nplt.xlabel('Número de correlações')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# uma versão do cálculo de correlações mais altas que não inclui\n# atributos relacionados a indicações e vitórias \n# (que serão utilizados como classes nos modelos criados)\n\nnumber_of_corrs = []\nfor threshold in CORR_THRESHOLDS:\n    corrs = large_corrs(sorted_corrs, threshold, include_nominations_and_victories=False)\n    number_of_corrs.append(len(corrs))\n    \nplt.plot(CORR_THRESHOLDS, number_of_corrs)\nplt.xlabel('Correlação mínima definida')\nplt.ylabel('Número de correlações encontradas')\nplt.title('Correlações encontradas x correlação mínima (inclui indicações)')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# escolhendo um novo threshold arbitrário para o caso sem indicações\nCORR_THRESHOLD = 0.15\n        \ncorrs = large_corrs(sorted_corrs, CORR_THRESHOLD, include_nominations_and_victories=False)\n\nprint(f'{len(corrs)} correlations found larger than {CORR_THRESHOLD} (without nominations and victories):')\ncorrs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# contagem das colunas que mais aparecem nas correlações, não incluindo indicações\n\ncounts = {}\nfor a, b in corrs:\n    counts[a] = counts.get(a, 0) + 1\n    counts[b] = counts.get(b, 0) + 1\n\nsorted_counts = sorted(\n    [\n        (column, value) for column, value in counts.items()\n        if 'won_' not in column\n    ],\n    key=lambda x: x[1],\n)\nsorted_dict = {\n    column: value for column, value in sorted_counts\n}\n\nplt.barh(list(sorted_dict.keys()), list(sorted_dict.values()))\nplt.title('Atributos mais presentes nas maiores correlações (sem incluir indicações)')\nplt.ylabel('Atributo')\nplt.xlabel('Número de correlações')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Análise de componente principal\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# obtendo as colunas de atributos\ncolumns_attributes = columns_nominations = [\n    column for column in movies_metadata.columns\n    if column not in columns_nominations and\n    column not in columns_wins\n]\n\n# attribute columns\nattributes_data = movies_metadata[columns_attributes]\n\n# target columns\nnominated_at_least_once = movies_metadata['nominated_at_least_once']\nwon_at_least_once = movies_metadata['won_at_least_once']\n\n# Normalização dos dados\nX = attributes_data.to_numpy()\ny_nominations = nominated_at_least_once.to_numpy()\ny_wins = won_at_least_once.to_numpy()\n\nfig = plt.figure(1, figsize=(8, 6))\nax = Axes3D(fig, elev=-150, azim=110)\nX_reduced = PCA(n_components=3).fit_transform(X)\nax.scatter(\n    X_reduced[:, 0],\n    X_reduced[:, 1],\n    X_reduced[:, 2],\n    c=y_nominations,\n    cmap=plt.cm.Set1,\n    edgecolor=\"k\",\n    s=40,\n)\nax.set_title(\"Primeiros treês componentes principais\")\nax.set_xlabel(\"1o componente\")\nax.w_xaxis.set_ticklabels([])\nax.set_ylabel(\"2o componente\")\nax.w_yaxis.set_ticklabels([])\nax.set_zlabel(\"3o componente\")\nax.w_zaxis.set_ticklabels([])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}